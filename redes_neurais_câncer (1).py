# -*- coding: utf-8 -*-
"""redes_neurais_câncer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OZk9BgVyfy4hOpehxsX9DmpKfV4PdOib
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("tarekmasryo/cancer-risk-factors-dataset")

print("Path to dataset files:", path)

import pandas as pd
import os
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Caminho dos arquivos baixados
print(path)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical

pip install scikeras

from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, mutual_info_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline   # pipeline que aceita SMOTE

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, InputLayer
from tensorflow.keras.optimizers import Adam, RMSprop

from scikeras.wrappers import KerasClassifier

os.listdir(path)

df = pd.read_csv(os.path.join(path, "cancer-risk-factors.csv"))

df.head()

df.nunique()

## Observando as informações gerais

df.info()

"""Temos apenas 3 colunas em formato de objeto que precisarão ser trasformadas para ser utilizadas em redes neurais."""

df.describe()

df.describe(include="object")

df.isna().sum()

## A variável alvo será o risco de câncer, para avaliar se é baixo, médio ou alto. ##

"""Não temos valores ausentes, isso é ótimo"""

## variáveis numericas
df[["Age","Fruit_Veg_Intake","Air_Pollution",
    "Calcium_Intake","BMI","Overall_Risk_Score"]].describe()

import matplotlib.pyplot as plt
import seaborn as sns

# estilo mais bonito
sns.set(style="whitegrid")

# lista das variáveis
variaveis = ["BMI", "Overall_Risk_Score", "Age"]

plt.figure(figsize=(14, 4))

for i, var in enumerate(variaveis, 1):
    plt.subplot(1, 3, i)
    sns.histplot(df[var], kde=True)
    plt.xlabel(var)
    plt.ylabel("Frequência")

plt.tight_layout()

# salvar figura
plt.savefig("distribuicoes_variaveis.png", dpi=300, bbox_inches='tight')

plt.show()

sns.set(style="whitegrid")

variaveis = ["BMI", "Overall_Risk_Score", "Age"]

plt.figure(figsize=(16, 5))

for i, var in enumerate(variaveis, 1):
    plt.subplot(1, 3, i)
    sns.boxplot(data=df, x="Cancer_Type", y=var)
    plt.xlabel("Tipo de Câncer")
    plt.ylabel(var)
    plt.xticks(rotation=45)

plt.tight_layout()

plt.savefig("relacao_variaveis_cancer_type.png", dpi=300, bbox_inches='tight')
plt.show()

## avaliando as categoricas

for col in ["Cancer_Type","Risk_Level","Gender","Smoking","Physical_Activity_Level"]:
    print("\nDistribuição de", col)
    print(df[col].value_counts())

df.corr(numeric_only=True)

"""A idade média é de 63 anos. O valor médio do BMI indica sobre peso leve. O câncer de pele é o menos frequente, enquanto o de pulmão lidera o ranking. A variável resposta está desbalanceada, a quantidade de pacientes com risco médio é muito superior as demais."""

## Avaliando a correlação com a variável alvo



corr = df.corr(numeric_only=True)
plt.figure(figsize=(12,8))
sns.heatmap(corr, annot=False, cmap="viridis")
plt.show()

## apagar a coluna ID que não trás informações

df = df.drop(columns=["Patient_ID"])

## separando a variável alvo das demais
y = df["Risk_Level"]
X = df.drop(columns=["Risk_Level"])

## codificando a variável alvo
le = LabelEncoder()
y_encoded = le.fit_transform(y)
y_cat = to_categorical(y_encoded)

categorical_cols = ["Cancer_Type"]
numeric_cols = [col for col in X.columns if col not in categorical_cols]

## fazendo as transformações nas variáveis númericas e categoricas

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(), categorical_cols)
    ]
)

X_processed = preprocessor.fit_transform(X)

## separando as variáveis em treino e teste

X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y_cat,
    test_size=0.20,
    random_state=42,
    stratify=y_cat
)

# 8. Construção do modelo
model = Sequential()

# Camada densa 1
model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))
model.add(Dropout(0.3))   # evitar overfitting

# Camada densa 2
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.3))

# Camada de saída (classes do Risk_Level)
model.add(Dense(y_cat.shape[1], activation='softmax'))

# Compilação
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 9. Treinamento do modelo
history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=50,
    batch_size=32,
    verbose=1
)

# 10. Avaliação no conjunto de teste
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

print("\nACCURACY:", accuracy_score(y_test_classes, y_pred_classes), "\n")
print(classification_report(y_test_classes, y_pred_classes, target_names=le.classes_))

## Perda e acurácia

import matplotlib.pyplot as plt

plt.figure(figsize=(12,5))

# Loss
plt.subplot(1,2,1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss durante o treinamento')
plt.xlabel('Épocas')
plt.ylabel('Loss')
plt.legend(['treino', 'validação'])

# Accuracy
plt.subplot(1,2,2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Acurácia durante o treinamento')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend(['treino', 'validação'])

plt.show()

from sklearn.utils.class_weight import compute_class_weight

def create_model(optimizer='adam', dropout_rate=0.3, neurons1=64, neurons2=32):
    """
    Função para criar e compilar o modelo Keras.
    Parâmetros são expostos para otimização com GridSearchCV.
    """
    model = Sequential([
        # Camada de entrada/primeira camada densa
        Dense(neurons1, activation='relu', input_dim=X_train.shape[1]),
        Dropout(dropout_rate),

        # Segunda camada densa
        Dense(neurons2, activation='relu'),
        Dropout(dropout_rate),

        # Camada de saída (Número de classes)
        Dense(y_cat.shape[1], activation='softmax')
    ])

    # Compilação
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

"""Avaliando o desequilibrio de classes."""

##pip uninstall scikit-learn -y

##pip install scikit-learn==1.3.2

# ===========================================================
# 12. Tratamento do Desequilíbrio de Classes e Otimização

from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.utils.class_weight import compute_class_weight

# 12.1. Cálculo dos Pesos de Classe (Class Weight)
# Continuamos usando as labels inteiras para o cálculo dos pesos.
y_train_labels = np.argmax(y_train, axis=1)

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train_labels),
    y=y_train_labels
)

class_weight_dict = dict(enumerate(class_weights))
print("\nPesos de Classe Calculados:", class_weight_dict)


# 12.2. Envoltório KerasClassifier e GridSearch
# O KerasClassifier usará os pesos e, graças à nova função de perda,
# aceitará os rótulos de inteiros do GridSearch.

keras_model = KerasClassifier(
    model=create_model,
    verbose=0,
    epochs=50,
    batch_size=32,
    class_weight=class_weight_dict
)

# Define a grade de hiperparâmetros
param_grid = {
    'optimizer': ['adam', 'rmsprop'],
    'model__dropout_rate': [0.2, 0.4],
    'model__neurons1': [64, 128],
    'epochs': [50, 75]
}

# Configuração do Grid Search com 3-fold Cross-Validation
grid = GridSearchCV(
    estimator=keras_model,
    param_grid=param_grid,
    n_jobs=-1,
    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),
    scoring='accuracy',
    verbose=1
)

print("\nIniciando Grid Search...")
# CORREÇÃO FINAL: Usamos y_train_labels (inteiros) para o fit.
# A nova função de perda (sparse) resolve a incompatibilidade interna.
grid_result = grid.fit(X_train, y_train_labels)


# 12.3. Resumo dos Resultados do Grid Search

print("\n=========================================================")
print("  RESULTADOS DO GRID SEARCH (MODELO OTIMIZADO)")
print("=========================================================")
print(f"Melhor Acurácia na Validação: {grid_result.best_score_:.4f}")
print("Melhores Hiperparâmetros:", grid_result.best_params_)

best_model_optimized = grid_result.best_estimator_


# 12.4. Avaliação do Melhor Modelo no Conjunto de Teste

print("\n12.4. Avaliação do Modelo Otimizado no Conjunto de Teste")

y_pred_optimized = best_model_optimized.predict(X_test)

# Converte de volta para as labels originais para o classification_report
y_pred_optimized_classes = y_pred_optimized.flatten()
y_test_classes_optimized = np.argmax(y_test, axis=1)

accuracy_optimized = accuracy_score(y_test_classes_optimized, y_pred_optimized_classes)

print("\nACCURACY DO MODELO OTIMIZADO:", accuracy_optimized, "\n")
print(classification_report(y_test_classes_optimized, y_pred_optimized_classes, target_names=le.classes_))

# 13. Comparação Final de Desempenho

print("\n=========================================================")
print("  COMPARAÇÃO FINAL DE DESEMPENHO (ACCURACY NO TESTE)")
print("=========================================================")

# Acurácia do modelo ANTERIOR do seu código original
accuracy_original = accuracy_score(y_test_classes, y_pred_classes)

print(f"Modelo 1 (Original, Sem Otimização): {accuracy_original:.4f}")
print(f"Modelo 2 (Otimizado, Com Class Weight e Grid Search): {accuracy_optimized:.4f}")

best_model_optimized = grid_result.best_estimator_

## matriz de confusão

# 14. Matriz de Confusão para Visualização do Modelo Otimizado
#

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm_optimized = confusion_matrix(y_test_classes_optimized, y_pred_optimized_classes)
labels = le.classes_ # Nomes das classes: Low, Medium, High

plt.figure(figsize=(8, 6))
#
sns.heatmap(
    cm_optimized,
    annot=True,
    fmt='d',
    cmap='Blues',
    xticklabels=labels,
    yticklabels=labels
)
plt.title('Matriz de Confusão do Modelo Otimizado')
plt.ylabel('Rótulo Verdadeiro')
plt.xlabel('Rótulo Predito')
plt.show()

print("\nAnálise Visual: A Matriz de Confusão mostra quantos casos de cada risco foram classificados corretamente (diagonal principal).")

## testar novas arquiteturas e funções de ativação

# 11. Função para criar o modelo (Revisada para Ativação)

# Certifique-se de que a variável X_train está acessível aqui
def create_model(optimizer='adam', dropout_rate=0.3, neurons1=64, neurons2=32, activation='relu'):
    """
    Função para criar e compilar o modelo Keras.
    Adiciona 'activation' como um parâmetro otimizável.
    """
    model = Sequential([
        # Camada de entrada/primeira camada densa
        Dense(neurons1, activation=activation, input_dim=X_train.shape[1]),
        Dropout(dropout_rate),

        # Segunda camada densa
        Dense(neurons2, activation=activation), # Usa a ativação variável
        Dropout(dropout_rate),

        # Camada de saída (Não muda, deve ser 'softmax')
        Dense(y_cat.shape[1], activation='softmax')
    ])

    # Compilação
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy', # MANTIDA a correção do erro anterior
        metrics=['accuracy']
    )
    return model



# 12.5. Otimização 2: Explorando Ativação e Arquitetura

# As variáveis y_train_labels e class_weight_dict permanecem as mesmas
# do bloco 12.1 anterior.

# Inicializa o KerasClassifier
keras_model_v2 = KerasClassifier(
    model=create_model,
    verbose=0,
    epochs=50,
    batch_size=32,
    class_weight=class_weight_dict
)

# Define a NOVA grade de hiperparâmetros
param_grid_v2 = {
    # Testar otimizadores e taxas de aprendizado comuns
    'optimizer': ['adam', 'sgd'],

    # Testar funções de ativação populares
    'model__activation': ['relu', 'tanh', 'elu'],

    # Testar arquitetura: 64 neurônios na 1ª e 16 ou 32 na 2ª
    'model__neurons1': [64],
    'model__neurons2': [16, 32],

    # Manter a taxa de dropout dentro de um intervalo razoável
    'model__dropout_rate': [0.2, 0.4]

    # Total de combinações: 2 * 3 * 1 * 2 * 2 = 24 combinações
}

# Configuração do Grid Search (mantemos o StratifiedKFold)
grid_v2 = GridSearchCV(
    estimator=keras_model_v2,
    param_grid=param_grid_v2,
    n_jobs=-1,
    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),
    scoring='accuracy',
    verbose=1
)

print("\nIniciando Grid Search V2 (Ativação e Arquitetura)...")
grid_result_v2 = grid_v2.fit(X_train, y_train_labels)


# 12.6. Resumo e Avaliação do Modelo V2

print("\n=========================================================")
print("  RESULTADOS DO GRID SEARCH V2 (ATIV./ARQUIT.)")
print("=========================================================")
print(f"Melhor Acurácia na Validação (V2): {grid_result_v2.best_score_:.4f}")
print("Melhores Hiperparâmetros (V2):", grid_result_v2.best_params_)

best_model_optimized_v2 = grid_result_v2.best_estimator_

print("\n12.7. Avaliação do Melhor Modelo V2 no Conjunto de Teste")

y_pred_optimized_v2 = best_model_optimized_v2.predict(X_test)

y_pred_v2_classes = y_pred_optimized_v2.flatten()

accuracy_optimized_v2 = accuracy_score(y_test_classes_optimized, y_pred_v2_classes)

print("\nACCURACY DO MODELO OTIMIZADO V2:", accuracy_optimized_v2, "\n")
print(classification_report(y_test_classes_optimized, y_pred_v2_classes, target_names=le.classes_))

print(best_model_optimized_v2.get_params())

best_model_optimized_v2.model_.summary()

best_model_optimized_v2 = grid_result.best_estimator_
best_model_optimized_v2.get_params()

y_pred_v2 = best_model_optimized_v2.predict(X_test)
y_pred_v2 = y_pred_v2.flatten()

y_true_v2 = y_test_classes_optimized

# 3. Matriz de Confusão
cm_v2 = confusion_matrix(y_true_v2, y_pred_v2)

# 4. Plot da Matriz
plt.figure(figsize=(6,4))
sns.heatmap(cm_v2, annot=True, fmt="d", cmap="Blues",
            xticklabels=le.classes_,
            yticklabels=le.classes_)
plt.xlabel("Predito")
plt.ylabel("Real")
plt.show()

"""expandindo o param_grid para incluir funções de ativações mais usuais e arquitetura com menos neurônios."""

# Melhor Modelo com Dropout Reforçado (0.5)


BEST_OPTIMIZER = 'adam'
BEST_ACTIVATION = 'relu'
BEST_NEURONS1 = 128
BEST_NEURONS2 = 32
BEST_EPOCHS = 75
NEW_DROPOUT_RATE = 0.5    # Aumento do Dropout para regularização extra

print(f"\nConstruindo Modelo A com Dropout Reforçado ({NEW_DROPOUT_RATE})...")

# Criação do modelo (usando a função create_model e os melhores parâmetros)
model_a = create_model(
    optimizer=BEST_OPTIMIZER,
    dropout_rate=NEW_DROPOUT_RATE,  # Novo valor de Dropout
    neurons1=BEST_NEURONS1,
    neurons2=BEST_NEURONS2,
    activation=BEST_ACTIVATION
)

# Treinamento do Modelo A (com os pesos de classe e o número de épocas otimizado)
history_a = model_a.fit(
    X_train, y_train_labels, # Usando y_train_labels (inteiros) e sparse_categorical_crossentropy
    epochs=BEST_EPOCHS,
    batch_size=32,
    verbose=0,
    validation_split=0.2,
    class_weight=class_weight_dict # Manter o tratamento do desequilíbrio
)

# Avaliação do Modelo A
y_pred_a = model_a.predict(X_test)
y_pred_a_classes = np.argmax(y_pred_a, axis=1)

accuracy_a = accuracy_score(y_test_classes_optimized, y_pred_a_classes)

print("\n--- Resultados do Modelo A (Dropout Reforçado) ---")
print(f"ACCURACY (Teste): {accuracy_a:.4f}\n")
print(classification_report(y_test_classes_optimized, y_pred_a_classes, target_names=le.classes_))

# Melhor Modelo com Ativação Sigmoid

SIGMOID_ACTIVATION = 'sigmoid' # Nova função de ativação
BEST_OPTIMIZER = 'adam'    # Exemplo

print(f"\nConstruindo Modelo B com Ativação Sigmoid...")

# Criação do modelo (mudando apenas a ativação para Sigmoid)
model_b = create_model(
    optimizer=BEST_OPTIMIZER,
    dropout_rate=0.3, # Usando um dropout padrão
    neurons1=BEST_NEURONS1,
    neurons2=BEST_NEURONS2,
    activation=SIGMOID_ACTIVATION # Nova Ativação
)

# Treinamento do Modelo B
history_b = model_b.fit(
    X_train, y_train_labels,
    epochs=BEST_EPOCHS,
    batch_size=32,
    verbose=0,
    validation_split=0.2,
    class_weight=class_weight_dict
)

# Avaliação do Modelo B
y_pred_b = model_b.predict(X_test)
y_pred_b_classes = np.argmax(y_pred_b, axis=1)

accuracy_b = accuracy_score(y_test_classes_optimized, y_pred_b_classes)

print("\n--- Resultados do Modelo B (Ativação Sigmoid) ---")
print(f"ACCURACY (Teste): {accuracy_b:.4f}\n")
print(classification_report(y_test_classes_optimized, y_pred_b_classes, target_names=le.classes_))

## Os ultimos dois modelos não mostraram resultados superiores